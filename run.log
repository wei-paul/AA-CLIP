AA-CLIP TRAINING WITH CROSS-ATTENTION + FEEDBACK LOOP
======================================================================
Dataset: VisA
Save path: ckpt/visa_cross_attn_feedback_fixed1219
Number of feedback loops: 3

Epoch Schedule:
  Loop 1: 5 text epochs, 20 image epochs, LR factor: 1.0000
  Loop 2: 3 text epochs, 10 image epochs, LR factor: 0.5000
  Loop 3: 2 text epochs, 5 image epochs, LR factor: 0.2500

Cross-attention heads: 8
======================================================================

Device: cuda:0

Loading CLIP models...
  clip_surgery loaded
  clip_model loaded
  AdaptedCLIPWithCrossAttention loaded

[PARAMETERS]
  Stage 1: text_adapter (2,359,296) + text_cross_attn (2,362,368)
  Stage 2: image_adapter (10,223,616) + image_cross_attn (2,755,840)

======================================================================
LOADING PRE-TRAINED BASE TEXT ADAPTER
======================================================================
  Path: ./ckpt/VisA_base_full_1216/text_adapter.pth
  ✓ Base text adapter loaded successfully!

======================================================================
LOADING PRE-TRAINED BASE IMAGE ADAPTER
======================================================================
  Path: ./ckpt/VisA_base_full_1216/image_adapter.pth
  ✓ Base image adapter loaded successfully!

Loading dataset: VisA
  Text dataset: 2162 samples
  Image dataset: 2162 samples

######################################################################
#  FEEDBACK LOOP 1 / 3
######################################################################

Loop 1 Configuration:
  Text epochs: 5
  Image epochs: 20
  Text LR: 0.00001000
  Image LR: 0.00050000

======================================================================
LOOP 1 - STAGE 1: TEXT ADAPTER TRAINING
======================================================================

======================================================================
LOOP 1 | EPOCH 0/4 - STAGE 1: TEXT CROSS-ATTENTION
Image features: FROZEN clip_surgery
======================================================================
Loop 1 Epoch 0:   0%|                                                                           | 0/136 [00:00<?, ?it/s]
============================================================
BATCH 0 DEBUG (Loop 1)
============================================================
  image: torch.Size([16, 3, 518, 518]), class_names: ['pcb4', 'pcb2', 'pcb3', 'pcb2', 'pcb2', 'capsules', 'capsules', 'pcb1', 'candle', 'capsules', 'cashew', 'chewinggum', 'macaroni2', 'macaroni2', 'pcb3', 'fryum']

============================================================
COMPUTING IMAGE CONTEXT (FROZEN - Loop 1)
============================================================
[INPUT] image shape: torch.Size([16, 3, 518, 518])
[OUTPUT] image_context shape: torch.Size([16, 1369, 768])
[SOURCE] FROZEN clip_surgery
============================================================


[SET IMAGE CONTEXT for Stage 1]
  shape: torch.Size([16, 1369, 768])

======================================================================
ENCODE_TEXT (Stage 1 with Cross-Attention)
======================================================================
[INPUT] text shape: torch.Size([6, 77])
[CONFIG] cross-attention enabled: True

>>> STAGE 1 CROSS-ATTENTION (text→image) <<<
    Scaling factor: 0.1

[BATCH SIZE MISMATCH HANDLING]
  B_text=6, B_img=16
  Aggregating image context: mean across batch dimension
  After aggregation: image_context shape: torch.Size([6, 1369, 768])

============================================================
TEXT CROSS-ATTENTION MODULE DEBUG (Stage 1)
============================================================
[INPUT] text_features shape: torch.Size([6, 77, 768])
[INPUT] image_context shape: torch.Size([6, 1369, 768])
[CONFIG] num_heads: 8, head_dim: 96
[CONFIG] scale factor: 0.102062

[PROJECTION]
  Q shape: torch.Size([6, 77, 768]), K shape: torch.Size([6, 1369, 768]), V shape: torch.Size([6, 1369, 768])
[ATTENTION] attn_weights shape: torch.Size([6, 8, 77, 1369])
[OUTPUT] shape: torch.Size([6, 77, 768])
============================================================

    cross_out norm before: 1.2724
    cross_out norm after: 18.8025
>>> CROSS-ATTENTION COMPLETE <<<

[OUTPUT] shape: torch.Size([6, 768])
======================================================================


======================================================================
ENCODE_TEXT (Stage 1 with Cross-Attention)
======================================================================
[INPUT] text shape: torch.Size([10, 77])
[CONFIG] cross-attention enabled: True

>>> STAGE 1 CROSS-ATTENTION (text→image) <<<
    Scaling factor: 0.1

[BATCH SIZE MISMATCH HANDLING]
  B_text=10, B_img=16
  Aggregating image context: mean across batch dimension
  After aggregation: image_context shape: torch.Size([10, 1369, 768])

============================================================
TEXT CROSS-ATTENTION MODULE DEBUG (Stage 1)
============================================================
[INPUT] text_features shape: torch.Size([10, 77, 768])
[INPUT] image_context shape: torch.Size([10, 1369, 768])
[CONFIG] num_heads: 8, head_dim: 96
[CONFIG] scale factor: 0.102062

[PROJECTION]
  Q shape: torch.Size([10, 77, 768]), K shape: torch.Size([10, 1369, 768]), V shape: torch.Size([10, 1369, 768])
[ATTENTION] attn_weights shape: torch.Size([10, 8, 77, 1369])
[OUTPUT] shape: torch.Size([10, 77, 768])
============================================================

    cross_out norm before: 1.2724
    cross_out norm after: 18.8130
>>> CROSS-ATTENTION COMPLETE <<<

[OUTPUT] shape: torch.Size([10, 768])
======================================================================


======================================================================
ENCODE_TEXT (Stage 1 with Cross-Attention)
======================================================================
[INPUT] text shape: torch.Size([6, 77])
[CONFIG] cross-attention enabled: True

>>> STAGE 1 CROSS-ATTENTION (text→image) <<<
    Scaling factor: 0.1

[BATCH SIZE MISMATCH HANDLING]
  B_text=6, B_img=16
  Aggregating image context: mean across batch dimension
  After aggregation: image_context shape: torch.Size([6, 1369, 768])

============================================================
TEXT CROSS-ATTENTION MODULE DEBUG (Stage 1)
============================================================
[INPUT] text_features shape: torch.Size([6, 77, 768])
[INPUT] image_context shape: torch.Size([6, 1369, 768])
[CONFIG] num_heads: 8, head_dim: 96
[CONFIG] scale factor: 0.102062

[PROJECTION]
  Q shape: torch.Size([6, 77, 768]), K shape: torch.Size([6, 1369, 768]), V shape: torch.Size([6, 1369, 768])
[ATTENTION] attn_weights shape: torch.Size([6, 8, 77, 1369])
[OUTPUT] shape: torch.Size([6, 77, 768])
============================================================

    cross_out norm before: 1.2724
    cross_out norm after: 18.8184
>>> CROSS-ATTENTION COMPLETE <<<

[OUTPUT] shape: torch.Size([6, 768])
======================================================================


======================================================================
ENCODE_TEXT (Stage 1 with Cross-Attention)
======================================================================
[INPUT] text shape: torch.Size([10, 77])
[CONFIG] cross-attention enabled: True

>>> STAGE 1 CROSS-ATTENTION (text→image) <<<
    Scaling factor: 0.1

[BATCH SIZE MISMATCH HANDLING]
  B_text=10, B_img=16
  Aggregating image context: mean across batch dimension
  After aggregation: image_context shape: torch.Size([10, 1369, 768])

============================================================
TEXT CROSS-ATTENTION MODULE DEBUG (Stage 1)
============================================================
[INPUT] text_features shape: torch.Size([10, 77, 768])
[INPUT] image_context shape: torch.Size([10, 1369, 768])
[CONFIG] num_heads: 8, head_dim: 96
[CONFIG] scale factor: 0.102062

[PROJECTION]
  Q shape: torch.Size([10, 77, 768]), K shape: torch.Size([10, 1369, 768]), V shape: torch.Size([10, 1369, 768])
[ATTENTION] attn_weights shape: torch.Size([10, 8, 77, 1369])
[OUTPUT] shape: torch.Size([10, 77, 768])
============================================================

    cross_out norm before: 1.2724
    cross_out norm after: 18.8359
>>> CROSS-ATTENTION COMPLETE <<<

[OUTPUT] shape: torch.Size([10, 768])
======================================================================


======================================================================
ENCODE_TEXT (Stage 1 with Cross-Attention)
======================================================================
[INPUT] text shape: torch.Size([6, 77])
[CONFIG] cross-attention enabled: True

>>> STAGE 1 CROSS-ATTENTION (text→image) <<<
    Scaling factor: 0.1

[BATCH SIZE MISMATCH HANDLING]
  B_text=6, B_img=16
  Aggregating image context: mean across batch dimension
  After aggregation: image_context shape: torch.Size([6, 1369, 768])

============================================================
TEXT CROSS-ATTENTION MODULE DEBUG (Stage 1)
============================================================
[INPUT] text_features shape: torch.Size([6, 77, 768])
[INPUT] image_context shape: torch.Size([6, 1369, 768])
[CONFIG] num_heads: 8, head_dim: 96
[CONFIG] scale factor: 0.102062

[PROJECTION]
  Q shape: torch.Size([6, 77, 768]), K shape: torch.Size([6, 1369, 768]), V shape: torch.Size([6, 1369, 768])
[ATTENTION] attn_weights shape: torch.Size([6, 8, 77, 1369])
[OUTPUT] shape: torch.Size([6, 77, 768])
============================================================

    cross_out norm before: 1.2724
    cross_out norm after: 18.8282
>>> CROSS-ATTENTION COMPLETE <<<

[OUTPUT] shape: torch.Size([6, 768])
======================================================================


======================================================================
ENCODE_TEXT (Stage 1 with Cross-Attention)
======================================================================
[INPUT] text shape: torch.Size([10, 77])
[CONFIG] cross-attention enabled: True

>>> STAGE 1 CROSS-ATTENTION (text→image) <<<
    Scaling factor: 0.1

[BATCH SIZE MISMATCH HANDLING]
  B_text=10, B_img=16
  Aggregating image context: mean across batch dimension
  After aggregation: image_context shape: torch.Size([10, 1369, 768])

============================================================
TEXT CROSS-ATTENTION MODULE DEBUG (Stage 1)
============================================================
[INPUT] text_features shape: torch.Size([10, 77, 768])
[INPUT] image_context shape: torch.Size([10, 1369, 768])
[CONFIG] num_heads: 8, head_dim: 96
[CONFIG] scale factor: 0.102062

[PROJECTION]
  Q shape: torch.Size([10, 77, 768]), K shape: torch.Size([10, 1369, 768]), V shape: torch.Size([10, 1369, 768])
[ATTENTION] attn_weights shape: torch.Size([10, 8, 77, 1369])
[OUTPUT] shape: torch.Size([10, 77, 768])
============================================================

    cross_out norm before: 1.2724
    cross_out norm after: 18.8449
>>> CROSS-ATTENTION COMPLETE <<<

[OUTPUT] shape: torch.Size([10, 768])
======================================================================


======================================================================
ENCODE_TEXT (Stage 1 with Cross-Attention)
======================================================================
[INPUT] text shape: torch.Size([6, 77])
[CONFIG] cross-attention enabled: True

>>> STAGE 1 CROSS-ATTENTION (text→image) <<<
    Scaling factor: 0.1

[BATCH SIZE MISMATCH HANDLING]
  B_text=6, B_img=16
  Aggregating image context: mean across batch dimension
  After aggregation: image_context shape: torch.Size([6, 1369, 768])

============================================================
TEXT CROSS-ATTENTION MODULE DEBUG (Stage 1)
============================================================
[INPUT] text_features shape: torch.Size([6, 77, 768])
[INPUT] image_context shape: torch.Size([6, 1369, 768])
[CONFIG] num_heads: 8, head_dim: 96
[CONFIG] scale factor: 0.102062

[PROJECTION]
  Q shape: torch.Size([6, 77, 768]), K shape: torch.Size([6, 1369, 768]), V shape: torch.Size([6, 1369, 768])
[ATTENTION] attn_weights shape: torch.Size([6, 8, 77, 1369])
[OUTPUT] shape: torch.Size([6, 77, 768])
============================================================

    cross_out norm before: 1.2724
    cross_out norm after: 18.8137
>>> CROSS-ATTENTION COMPLETE <<<

[OUTPUT] shape: torch.Size([6, 768])
======================================================================


======================================================================
ENCODE_TEXT (Stage 1 with Cross-Attention)
======================================================================
[INPUT] text shape: torch.Size([10, 77])
[CONFIG] cross-attention enabled: True

>>> STAGE 1 CROSS-ATTENTION (text→image) <<<
    Scaling factor: 0.1

[BATCH SIZE MISMATCH HANDLING]
  B_text=10, B_img=16
  Aggregating image context: mean across batch dimension
  After aggregation: image_context shape: torch.Size([10, 1369, 768])

============================================================
TEXT CROSS-ATTENTION MODULE DEBUG (Stage 1)
============================================================
[INPUT] text_features shape: torch.Size([10, 77, 768])
[INPUT] image_context shape: torch.Size([10, 1369, 768])
[CONFIG] num_heads: 8, head_dim: 96
[CONFIG] scale factor: 0.102062

[PROJECTION]
  Q shape: torch.Size([10, 77, 768]), K shape: torch.Size([10, 1369, 768]), V shape: torch.Size([10, 1369, 768])
[ATTENTION] attn_weights shape: torch.Size([10, 8, 77, 1369])
[OUTPUT] shape: torch.Size([10, 77, 768])
============================================================

    cross_out norm before: 1.2724
    cross_out norm after: 18.8269
>>> CROSS-ATTENTION COMPLETE <<<

[OUTPUT] shape: torch.Size([10, 768])
======================================================================


======================================================================
ENCODE_TEXT (Stage 1 with Cross-Attention)
======================================================================
[INPUT] text shape: torch.Size([6, 77])
[CONFIG] cross-attention enabled: True

>>> STAGE 1 CROSS-ATTENTION (text→image) <<<
    Scaling factor: 0.1

[BATCH SIZE MISMATCH HANDLING]
  B_text=6, B_img=16
  Aggregating image context: mean across batch dimension
  After aggregation: image_context shape: torch.Size([6, 1369, 768])

============================================================
TEXT CROSS-ATTENTION MODULE DEBUG (Stage 1)
============================================================
[INPUT] text_features shape: torch.Size([6, 77, 768])
[INPUT] image_context shape: torch.Size([6, 1369, 768])
[CONFIG] num_heads: 8, head_dim: 96
[CONFIG] scale factor: 0.102062

[PROJECTION]
  Q shape: torch.Size([6, 77, 768]), K shape: torch.Size([6, 1369, 768]), V shape: torch.Size([6, 1369, 768])
[ATTENTION] attn_weights shape: torch.Size([6, 8, 77, 1369])
[OUTPUT] shape: torch.Size([6, 77, 768])
============================================================

    cross_out norm before: 1.2724
    cross_out norm after: 18.7819
>>> CROSS-ATTENTION COMPLETE <<<

[OUTPUT] shape: torch.Size([6, 768])
======================================================================


======================================================================
ENCODE_TEXT (Stage 1 with Cross-Attention)
======================================================================
[INPUT] text shape: torch.Size([10, 77])
[CONFIG] cross-attention enabled: True

>>> STAGE 1 CROSS-ATTENTION (text→image) <<<
    Scaling factor: 0.1

[BATCH SIZE MISMATCH HANDLING]
  B_text=10, B_img=16
  Aggregating image context: mean across batch dimension
  After aggregation: image_context shape: torch.Size([10, 1369, 768])

============================================================
TEXT CROSS-ATTENTION MODULE DEBUG (Stage 1)
============================================================
[INPUT] text_features shape: torch.Size([10, 77, 768])
[INPUT] image_context shape: torch.Size([10, 1369, 768])
[CONFIG] num_heads: 8, head_dim: 96
[CONFIG] scale factor: 0.102062

[PROJECTION]
  Q shape: torch.Size([10, 77, 768]), K shape: torch.Size([10, 1369, 768]), V shape: torch.Size([10, 1369, 768])
[ATTENTION] attn_weights shape: torch.Size([10, 8, 77, 1369])
[OUTPUT] shape: torch.Size([10, 77, 768])
============================================================

    cross_out norm before: 1.2724
    cross_out norm after: 18.7908
>>> CROSS-ATTENTION COMPLETE <<<

[OUTPUT] shape: torch.Size([10, 768])
======================================================================


======================================================================
ENCODE_TEXT (Stage 1 with Cross-Attention)
======================================================================
[INPUT] text shape: torch.Size([6, 77])
[CONFIG] cross-attention enabled: True

>>> STAGE 1 CROSS-ATTENTION (text→image) <<<
    Scaling factor: 0.1

[BATCH SIZE MISMATCH HANDLING]
  B_text=6, B_img=16
  Aggregating image context: mean across batch dimension
  After aggregation: image_context shape: torch.Size([6, 1369, 768])

============================================================
TEXT CROSS-ATTENTION MODULE DEBUG (Stage 1)
============================================================
[INPUT] text_features shape: torch.Size([6, 77, 768])
[INPUT] image_context shape: torch.Size([6, 1369, 768])
[CONFIG] num_heads: 8, head_dim: 96
[CONFIG] scale factor: 0.102062

[PROJECTION]
  Q shape: torch.Size([6, 77, 768]), K shape: torch.Size([6, 1369, 768]), V shape: torch.Size([6, 1369, 768])
[ATTENTION] attn_weights shape: torch.Size([6, 8, 77, 1369])
[OUTPUT] shape: torch.Size([6, 77, 768])
============================================================

    cross_out norm before: 1.2724
    cross_out norm after: 18.8000
>>> CROSS-ATTENTION COMPLETE <<<

[OUTPUT] shape: torch.Size([6, 768])
======================================================================


======================================================================
ENCODE_TEXT (Stage 1 with Cross-Attention)
======================================================================
[INPUT] text shape: torch.Size([10, 77])
[CONFIG] cross-attention enabled: True

>>> STAGE 1 CROSS-ATTENTION (text→image) <<<
    Scaling factor: 0.1

[BATCH SIZE MISMATCH HANDLING]
  B_text=10, B_img=16
  Aggregating image context: mean across batch dimension
  After aggregation: image_context shape: torch.Size([10, 1369, 768])

============================================================
TEXT CROSS-ATTENTION MODULE DEBUG (Stage 1)
============================================================
[INPUT] text_features shape: torch.Size([10, 77, 768])
[INPUT] image_context shape: torch.Size([10, 1369, 768])
[CONFIG] num_heads: 8, head_dim: 96
[CONFIG] scale factor: 0.102062

[PROJECTION]
  Q shape: torch.Size([10, 77, 768]), K shape: torch.Size([10, 1369, 768]), V shape: torch.Size([10, 1369, 768])
[ATTENTION] attn_weights shape: torch.Size([10, 8, 77, 1369])
[OUTPUT] shape: torch.Size([10, 77, 768])
============================================================

    cross_out norm before: 1.2724
    cross_out norm after: 18.8137
>>> CROSS-ATTENTION COMPLETE <<<

[OUTPUT] shape: torch.Size([10, 768])
======================================================================


======================================================================
ENCODE_TEXT (Stage 1 with Cross-Attention)
======================================================================
[INPUT] text shape: torch.Size([6, 77])
[CONFIG] cross-attention enabled: True

>>> STAGE 1 CROSS-ATTENTION (text→image) <<<
    Scaling factor: 0.1

[BATCH SIZE MISMATCH HANDLING]
  B_text=6, B_img=16
  Aggregating image context: mean across batch dimension
  After aggregation: image_context shape: torch.Size([6, 1369, 768])

============================================================
TEXT CROSS-ATTENTION MODULE DEBUG (Stage 1)
============================================================
[INPUT] text_features shape: torch.Size([6, 77, 768])
[INPUT] image_context shape: torch.Size([6, 1369, 768])
[CONFIG] num_heads: 8, head_dim: 96
[CONFIG] scale factor: 0.102062

[PROJECTION]
  Q shape: torch.Size([6, 77, 768]), K shape: torch.Size([6, 1369, 768]), V shape: torch.Size([6, 1369, 768])
[ATTENTION] attn_weights shape: torch.Size([6, 8, 77, 1369])
[OUTPUT] shape: torch.Size([6, 77, 768])
============================================================

    cross_out norm before: 1.2724
    cross_out norm after: 18.7958
>>> CROSS-ATTENTION COMPLETE <<<

[OUTPUT] shape: torch.Size([6, 768])
======================================================================


======================================================================
ENCODE_TEXT (Stage 1 with Cross-Attention)
======================================================================
[INPUT] text shape: torch.Size([10, 77])
[CONFIG] cross-attention enabled: True

>>> STAGE 1 CROSS-ATTENTION (text→image) <<<
    Scaling factor: 0.1

[BATCH SIZE MISMATCH HANDLING]
  B_text=10, B_img=16
  Aggregating image context: mean across batch dimension
  After aggregation: image_context shape: torch.Size([10, 1369, 768])

============================================================
TEXT CROSS-ATTENTION MODULE DEBUG (Stage 1)
============================================================
[INPUT] text_features shape: torch.Size([10, 77, 768])
[INPUT] image_context shape: torch.Size([10, 1369, 768])
[CONFIG] num_heads: 8, head_dim: 96
[CONFIG] scale factor: 0.102062

[PROJECTION]
  Q shape: torch.Size([10, 77, 768]), K shape: torch.Size([10, 1369, 768]), V shape: torch.Size([10, 1369, 768])
[ATTENTION] attn_weights shape: torch.Size([10, 8, 77, 1369])
[OUTPUT] shape: torch.Size([10, 77, 768])
============================================================

    cross_out norm before: 1.2724
    cross_out norm after: 18.8081
>>> CROSS-ATTENTION COMPLETE <<<

[OUTPUT] shape: torch.Size([10, 768])
======================================================================


======================================================================
ENCODE_TEXT (Stage 1 with Cross-Attention)
======================================================================
[INPUT] text shape: torch.Size([6, 77])
[CONFIG] cross-attention enabled: True

>>> STAGE 1 CROSS-ATTENTION (text→image) <<<
    Scaling factor: 0.1

[BATCH SIZE MISMATCH HANDLING]
  B_text=6, B_img=16
  Aggregating image context: mean across batch dimension
  After aggregation: image_context shape: torch.Size([6, 1369, 768])

============================================================
TEXT CROSS-ATTENTION MODULE DEBUG (Stage 1)
============================================================
[INPUT] text_features shape: torch.Size([6, 77, 768])
[INPUT] image_context shape: torch.Size([6, 1369, 768])
[CONFIG] num_heads: 8, head_dim: 96
[CONFIG] scale factor: 0.102062

[PROJECTION]
  Q shape: torch.Size([6, 77, 768]), K shape: torch.Size([6, 1369, 768]), V shape: torch.Size([6, 1369, 768])
[ATTENTION] attn_weights shape: torch.Size([6, 8, 77, 1369])
[OUTPUT] shape: torch.Size([6, 77, 768])
============================================================

    cross_out norm before: 1.2724
    cross_out norm after: 18.7969
>>> CROSS-ATTENTION COMPLETE <<<

[OUTPUT] shape: torch.Size([6, 768])
======================================================================


======================================================================
ENCODE_TEXT (Stage 1 with Cross-Attention)
======================================================================
[INPUT] text shape: torch.Size([10, 77])
[CONFIG] cross-attention enabled: True

>>> STAGE 1 CROSS-ATTENTION (text→image) <<<
    Scaling factor: 0.1

[BATCH SIZE MISMATCH HANDLING]
  B_text=10, B_img=16
  Aggregating image context: mean across batch dimension
  After aggregation: image_context shape: torch.Size([10, 1369, 768])

============================================================
TEXT CROSS-ATTENTION MODULE DEBUG (Stage 1)
============================================================
[INPUT] text_features shape: torch.Size([10, 77, 768])
[INPUT] image_context shape: torch.Size([10, 1369, 768])
[CONFIG] num_heads: 8, head_dim: 96
[CONFIG] scale factor: 0.102062

[PROJECTION]
  Q shape: torch.Size([10, 77, 768]), K shape: torch.Size([10, 1369, 768]), V shape: torch.Size([10, 1369, 768])
[ATTENTION] attn_weights shape: torch.Size([10, 8, 77, 1369])
[OUTPUT] shape: torch.Size([10, 77, 768])
============================================================

    cross_out norm before: 1.2724
    cross_out norm after: 18.8114
>>> CROSS-ATTENTION COMPLETE <<<

[OUTPUT] shape: torch.Size([10, 768])
======================================================================


======================================================================
ENCODE_TEXT (Stage 1 with Cross-Attention)
======================================================================
[INPUT] text shape: torch.Size([6, 77])
[CONFIG] cross-attention enabled: True

>>> STAGE 1 CROSS-ATTENTION (text→image) <<<
    Scaling factor: 0.1

[BATCH SIZE MISMATCH HANDLING]
  B_text=6, B_img=16
  Aggregating image context: mean across batch dimension
  After aggregation: image_context shape: torch.Size([6, 1369, 768])

============================================================
TEXT CROSS-ATTENTION MODULE DEBUG (Stage 1)
============================================================
[INPUT] text_features shape: torch.Size([6, 77, 768])
[INPUT] image_context shape: torch.Size([6, 1369, 768])
[CONFIG] num_heads: 8, head_dim: 96
[CONFIG] scale factor: 0.102062

[PROJECTION]
  Q shape: torch.Size([6, 77, 768]), K shape: torch.Size([6, 1369, 768]), V shape: torch.Size([6, 1369, 768])
[ATTENTION] attn_weights shape: torch.Size([6, 8, 77, 1369])
[OUTPUT] shape: torch.Size([6, 77, 768])
============================================================

    cross_out norm before: 1.2724
    cross_out norm after: 18.7780
>>> CROSS-ATTENTION COMPLETE <<<

[OUTPUT] shape: torch.Size([6, 768])
======================================================================


======================================================================
ENCODE_TEXT (Stage 1 with Cross-Attention)
======================================================================
[INPUT] text shape: torch.Size([10, 77])
[CONFIG] cross-attention enabled: True

>>> STAGE 1 CROSS-ATTENTION (text→image) <<<
    Scaling factor: 0.1

[BATCH SIZE MISMATCH HANDLING]
  B_text=10, B_img=16
  Aggregating image context: mean across batch dimension
  After aggregation: image_context shape: torch.Size([10, 1369, 768])

============================================================
TEXT CROSS-ATTENTION MODULE DEBUG (Stage 1)
============================================================
[INPUT] text_features shape: torch.Size([10, 77, 768])
[INPUT] image_context shape: torch.Size([10, 1369, 768])
[CONFIG] num_heads: 8, head_dim: 96
[CONFIG] scale factor: 0.102062

[PROJECTION]
  Q shape: torch.Size([10, 77, 768]), K shape: torch.Size([10, 1369, 768]), V shape: torch.Size([10, 1369, 768])
[ATTENTION] attn_weights shape: torch.Size([10, 8, 77, 1369])
[OUTPUT] shape: torch.Size([10, 77, 768])
============================================================

    cross_out norm before: 1.2724
    cross_out norm after: 18.7855
>>> CROSS-ATTENTION COMPLETE <<<

[OUTPUT] shape: torch.Size([10, 768])
======================================================================


======================================================================
ENCODE_TEXT (Stage 1 with Cross-Attention)
======================================================================
[INPUT] text shape: torch.Size([6, 77])
[CONFIG] cross-attention enabled: True

>>> STAGE 1 CROSS-ATTENTION (text→image) <<<
    Scaling factor: 0.1

[BATCH SIZE MISMATCH HANDLING]
  B_text=6, B_img=16
  Aggregating image context: mean across batch dimension
  After aggregation: image_context shape: torch.Size([6, 1369, 768])

============================================================
TEXT CROSS-ATTENTION MODULE DEBUG (Stage 1)
============================================================
[INPUT] text_features shape: torch.Size([6, 77, 768])
[INPUT] image_context shape: torch.Size([6, 1369, 768])
[CONFIG] num_heads: 8, head_dim: 96
[CONFIG] scale factor: 0.102062

[PROJECTION]
  Q shape: torch.Size([6, 77, 768]), K shape: torch.Size([6, 1369, 768]), V shape: torch.Size([6, 1369, 768])
[ATTENTION] attn_weights shape: torch.Size([6, 8, 77, 1369])
[OUTPUT] shape: torch.Size([6, 77, 768])
============================================================

    cross_out norm before: 1.2724
    cross_out norm after: 18.8426
>>> CROSS-ATTENTION COMPLETE <<<

[OUTPUT] shape: torch.Size([6, 768])
======================================================================


======================================================================
ENCODE_TEXT (Stage 1 with Cross-Attention)
======================================================================
[INPUT] text shape: torch.Size([10, 77])
[CONFIG] cross-attention enabled: True

>>> STAGE 1 CROSS-ATTENTION (text→image) <<<
    Scaling factor: 0.1

[BATCH SIZE MISMATCH HANDLING]
  B_text=10, B_img=16
  Aggregating image context: mean across batch dimension
  After aggregation: image_context shape: torch.Size([10, 1369, 768])

============================================================
TEXT CROSS-ATTENTION MODULE DEBUG (Stage 1)
============================================================
[INPUT] text_features shape: torch.Size([10, 77, 768])
[INPUT] image_context shape: torch.Size([10, 1369, 768])
[CONFIG] num_heads: 8, head_dim: 96
[CONFIG] scale factor: 0.102062

[PROJECTION]
  Q shape: torch.Size([10, 77, 768]), K shape: torch.Size([10, 1369, 768]), V shape: torch.Size([10, 1369, 768])
[ATTENTION] attn_weights shape: torch.Size([10, 8, 77, 1369])
[OUTPUT] shape: torch.Size([10, 77, 768])
============================================================

    cross_out norm before: 1.2724
    cross_out norm after: 18.8585
>>> CROSS-ATTENTION COMPLETE <<<

[OUTPUT] shape: torch.Size([10, 768])
======================================================================


[TEXT EMBEDDINGS]
  shape: torch.Size([16, 768, 2])

[LOSS] total: 0.993397

[GRADIENTS]
  text_adapter[0]: 0.423194
  text_adapter[1]: 0.418189
  text_adapter[2]: 0.389991
  text_adapter[3]: 0.884430
  text_cross_attn.q_proj.weight: 0.016428
  text_cross_attn.q_proj.bias: 0.000018
  text_cross_attn.k_proj.weight: 0.016870
  text_cross_attn.k_proj.bias: 0.000000
  text_cross_attn.v_proj.weight: 0.396847
  text_cross_attn.v_proj.bias: 0.312925
  text_cross_attn.out_proj.weight: 0.426076
  text_cross_attn.out_proj.bias: 0.326962
============================================================

Loop 1 Epoch 0:  65%|██████████████████████████████████████████▋                       | 88/136 [09:18<05:09,  6.45s/it]